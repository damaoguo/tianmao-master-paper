\chapter{基于HTTPS流量的HTTPS流量应用多视图特征识别方法的研究}\label{chap:AIBMF}

\section{引入}
我们对\emph{AIBMF}对加密应用程序标识的见解有三方面：
％
\emph{（i）} SSL /TLS协议本质上是移动应用程序客户端和服务器之间通信的一种语言，这种语言的具体表现是网络流\emph{i.e。}，它是一系列数据包；
％
\emph{（ii）}因为协议状态机是对网络流的总体抽象描述，所以可以从不同的协议状态信息中构造应用程序指纹。
％
\emph {（iii）}尽管SSL / TLS隐藏了网络流的有效负载，但仍然从加密连接中泄漏了旁信道协议状态信息。

\section{多视图特征}
模型中包含了三个视图，分别称为数据包大小（PS）视图，数据包内容类型（CT）视图和数据包有效载荷字节（PB）视图。

该框架包括三个模块：预处理，特征学习和识别。


This module first organizes raw network traffic into flows (\emph{i.e.}, the sample objects to be classified). 
%
整个流程的集合可以表示为 $D = \{{\{f_i\}}_{i=1}^{i=N}\}_{j=1}^{j=C}$ where $f_i$ means the $i^{th}$ flow. 
%
% In this paper, the flow objects defined by the $\{SRC_{IP}, SRC_{port}, DEST_{IP}, DEST_{port},$ $Transport Protocol\}$ tuple.
%
% and an inactivity timeout, with a default value of 60s.
%
由于已经有了流程对象，因此可以转向流程的数字矢量表示。


\emph{（i）}对于PS视图，通过计算前16个数据包的大小（用-1填充），我们形成了$ 16 $维矢量$ v_ {ps} $。

\emph{（ii）}对于CT视图，我们通过将值内容类型字段扩展为前16个数据包（用-1填充）来形成$ 16 $维矢量$ v_ {ct} $，其范围从0到255 。

\emph{（iii）}对于PB视图，通过将有效载荷字节值视为相应的ASCII码，我们形成一个$ 16 \ times64 = 1024 $维向量$v_{pb}$，然后进一步转换为0-255（ 用-1填充）。


\begin{itemize}

	\item \textbf{Feature learning from PB view:} 
	%
	We use a 1D-CNN network architecture to process the input numerical vector $v_{pb}$.
	%
	In the 1D-CNN, two-layer convolutional are used, the number of convolution kernels used in each layer is 64, and the size of the convolution kernel is $1 \times 3$, max pooling layer used. 
	%
	Therefore, raw payload byte sequence is transformed into a 64-dimensional vector $\alpha$.
	%
	\begin{equation}
		\alpha = \mathit{1\!D\!-\!C\!N\!N}(v_{pb})
	\end{equation}

	\item \textbf{Feature learning from PS view:}
	%
	The vector $v_{ps}$ is processed by 1D-CNN the same as payload byte sequence, the differences are that the input vector is packet size sequence and the input length is 16 here.
	%
	After 1D-CNN feature learning, packet size sequence is transformed into a 64-dimensional vector $\beta$.
	%
	\begin{equation}
		\beta = \mathit{1D\!-\!C\!N\!N}(v_{ps})
	\end{equation}
	%
	\item \textbf{Feature learning from CT view:} 
	%
	The content type is originally a discrete variable represented by a 257-dimensional one-hot vector which is very sparse, so we introduce the embedding operation which maps the sparse representation to a 16-dimensional real vector which incorporates contextual information about the content type.
	%
	% Embedding mathetextbfcally represents a mapping: $f:X \to Y$, which satisfies two properties: injective and structure-preserving.
	%
	The Embedding layer needs to learn a transform matrix whose shape is $ (vocab\_size, embedding\_dim) $.
	%
	The embedding layer is basically a matrix which can be considered a transformation from discrete and sparse 1-hot-vector into a continuous and dense latent space. 
	%
	Formally, 
	%
	\begin{equation}
		\gamma = \mathit{R\!N\!N}(Embedding(v_{ct}))
	\end{equation}
	%
\end{itemize}

\subsection{payload部分}

\subsection{parameter部分}
\citep{wiana2019}

\subsection{packet size部分}

\subsection{神经网络结构}
% =================================
% Fig. 03: Model architecture
% =================================
\begin{figure}[!htbp]
	\centering
	\includegraphics[width=0.80\textwidth]{AIBMF-model.pdf}
	\bicaption{AIBMF网络结构}{AIBMF Architecture}
	\label{fig:AIBMF_Architecture}
\end{figure}

\subsubsection{Identification Module:}
%
将三个不同的抽象特征连接在一起以形成192维向量。
% 
\begin{equation}
	\delta = \alpha \oplus \beta \oplus \gamma
\end{equation}
%
然后将其输入到完全连接的层。
%
完全连接层的输出\emph {i.e。}，$ x $，将用作softmax回归的输入，以识别流量。

三种不同的抽象特征共同优化同一类别目标，共同计算多类交叉熵损失，并通过反向传播算法更新三个神经网络的参数\cite{rumelhart1986learning}.
%
Mathematically, the probability that an output prediction $Y$ is app $a_j$, is determined by: 
\begin{equation}
p(Y=j|x,W,b)=\mathit{softmax_j}(\emph{\textbf{W}}x + \emph{\textbf{b}})
% =\frac{e^{w_i^TZ+b_i}}{\sum_je^{w_j^TZ+b_j}}
\end{equation}
where $W$ is a weight matrix between the fully connected layer and the softmax layer, and the $b$ is the bais vector.
% 
Then the model's prediction $y_{pd} $ is the class whose probability is maximal:
%
\begin{equation}
%
y_{pd}=argmax(p(Y=j|x,W,b)),\forall j \in \{1,2,3,...,C\}
\end{equation} 
%
Our neural network selects the cross entropy \cite{Boer2005A} as the loss function. 
%


\section{多视图识别模型评估}
\subsection{评估标准}
为了对AIBMF在交通数据上的识别性能进行合理有效的定量评估，本文介绍了一些基本指标：真阳性（TP），假阴性（FN），真阴性（TN）和假阳性（ FP）。 TP是分类为应用程序$ i $的流量确切属于应用程序$ i $的数量。 FN是分类为应用程序$ i $的流数，完全属于应用程序$ j $。 TN是分类为应用程序$ j $的流数，完全属于应用程序$ i $。 FP是分类为应用程序$ j $的流数，完全属于应用程序$ j $。


在训练阶段，\ emph {Accuracy（ACC）}用于指示模型识别能力的提高，并且改进了综合显示模型在识别HTTPS流量方面的性能。 准确率是在迭代训练过程中所有正确样本量与训练数据的比率，该比率是根据公式（7）计算的。


% ===========
% EQUATION:06
% ===========
\begin{equation}
ACC=\frac{TP+TN}{TP+TN+FP+FN}	
\end{equation}

在测试阶段，\ emph {Precision（P）}显示预测到应用程序$ i $的流量是实际应用程序$ i $，\ emph {Recall（R）}显示预测正确的流量与 属于应用程序$ i $的所有流，以及HTTPS流量的综合评估索引\ emph {F1}值都用作评估标准。 \ emph {P}根据公式（8a）计算； \ emph {R}根据公式（9a）计算； F1值是结合两个指标的综合评价指标，是根据公式（10a）计算的。 为了在所有20个应用程序上评估我们的方法，我们将平均值$ P $，$ R $，$ F_1 $ --- $ Macro \ Precision $，$ Macro \ Recall $，$ Macro \ F_1 $作为整体指标 式（8b），（9b），（10b）。 


% ===========
% EQUATION:07
\begin{subequations}
	\begin{equation}
	P=\frac{TP}{TP+FP}
	\end{equation}
	
	\begin{equation}
	Macro\ Precision=\frac{1}{20}\sum_{i=1}^{20}P_i
	\end{equation}
	
\end{subequations}

% ===========
% EQUATION:08
% ===========
\begin{subequations}
	\begin{equation}
	R=\frac{TP}{TP+FN}	
	\end{equation}
	
	\begin{equation}
	Macro\ Recall=\frac{1}{20}\sum_{i=1}^{20}R_i
	\end{equation}
\end{subequations}


% ===========
% EQUATION:09
% ===========
\begin{subequations}
	\begin{equation}
	F_1=2\frac{P\times R}{P+R}
	\end{equation}
	
	\begin{equation}
	Macro\ F_1=\frac{1}{20}\sum_{i=1}^{20}F_{1i}
	\end{equation}
\end{subequations}



\subsection{超参数的确定}
\subsubsection{单个样本packet数目确定}
% =================================
% Fig. 03: Model architecture
% =================================
\begin{figure}[!htbp]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
      \includegraphics[width=\textwidth]{Packet-count-all.eps}
      \caption{}
      \label{fig:oaspl_a}
    \end{subfigure}%
    ~% add desired spacing
    \begin{subfigure}[b]{0.45\textwidth}
      \includegraphics[width=\textwidth]{Packet-count-acc.eps}
      \caption{}
      \label{fig:oaspl_b}
    \end{subfigure}
    ~% add desired spacing

    \bicaption{总声压级。(a) 这是子图说明信息，(b) 这是子图说明信息。}{OASPL.(a) This is the explanation of subfig, (b) This is the explanation of subfig.}
    \label{fig:oaspl}
\end{figure}


\subsubsection{单个packet的payload字节数确定}

% =================================
% Fig. 03: Model architecture
% =================================
\begin{figure}[!htbp]
	\centering
	\includegraphics[width=0.80\textwidth]{Payload-size-acc.eps}
	\bicaption{packet size}{view comparation}
	\label{fig:payload size}
\end{figure}



\subsection{不同视图选择的评估}
% =================================
% Fig. 03: Model architecture
% =================================

\subsection{不同深度学习模型的评估}

\begin{figure}[!htbp]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
      \includegraphics[width=\textwidth]{AIBMF-training-loss.png}
      \caption{}
      \label{fig:oaspl_a}
    \end{subfigure}%
    ~% add desired spacing
    \begin{subfigure}[b]{0.45\textwidth}
      \includegraphics[width=\textwidth]{AIBMF-training-acc.png}
      \caption{}
      \label{fig:oaspl_b}
    \end{subfigure}
    ~% add desired spacing

    \bicaption{总声压级。(a) 这是子图说明信息，(b) 这是子图说明信息。}{OASPL.(a) This is the explanation of subfig, (b) This is the explanation of subfig.}
    \label{fig:oaspl}
\end{figure}

\subsection{传统方法和研究方法的对比}
% ===========
% Table 01:Statistics
% ===========
\begin{table}
	\caption{HTTPS Statistics}
	\setlength{\tabcolsep}{7mm}
	\begin{center}
		\begin{tabular}{| c | c | c |}
			\hline
			\textbf{统计特征} & \textbf{含义} & \textbf{是否特有？}\\
			\hline
			\hline
			Packet counts & Packet数量& 否\\
			\hline
			TTL max & TTL最大值 & 否\\
			\hline
			TTL min & TTL最小值 & 否\\
			\hline
			TTL mean & TTL平均值 & 否\\
			\hline
			TTL median & TTL中位数 & 否\\
			\hline
			TTL var & TTL方差 & 否\\
			\hline
			packet\_length max & packet长度最大值 & 否\\
			\hline
			packet\_length min & packet长度最小值 & 否\\
			\hline
			packet\_length mean & packet长度平均值 & 否\\
			\hline
			packet\_length median & packet长度中位数 & 否\\
			\hline
			packet\_length var & packet长度方差 & 否\\
			\hline	
			window max & 窗口最大值 & 否\\
			\hline
			window min & 窗口最小值 & 否\\
			\hline
			window mean & 窗口平均值 & 否\\
			\hline
			window median & 窗口中位数 & 否\\
			\hline
			window var & 窗口方差 & 否\\
			\hline
			session\_id\_length max & session id长度 & 否\\
			\hline	
			client\_extensions\_length max & client extensions长度最大值 & 是\\
			\hline
			client\_extensions\_length min & client extensions长度最小值 & 是\\
			\hline
			client\_extensions\_length mean & client extensions长度平均值 & 是\\
			\hline
			client\_extensions\_length median & client extensions长度中位数 & 是\\
			\hline
			client\_extensions\_length var & client extensions长度方差 & 是\\
			\hline
			client\_ciphers counts & 客户端加密组件种类 & 是\\
			\hline
			server\_cipher & 服务端加密组建类型 & 是\\
			\hline
		\end{tabular}
		\label{tab1}
	\end{center}
\end{table}

\begin{table}
	\caption{traffic identification based on statistical features only}
	\begin{center}
		\begin{tabular}{|c||c||c||c|}
			\hline
			\textbf{Machine learning algorithm} & \textbf{Precision} & \textbf{Recall} & \textbf{F1} \\
			\hline
			\hline
			Random Forest & 0.8805 & 0.8172 & 0.8407 \\
			\hline
			SVM-RBF & 0.9214 & 0.5754 & 0.6676 \\
			\hline
			DNN & 0.7362 & 0.6293 & 0.6562 \\
			\hline
			\textbf{AIBMF} & \textbf{0.918} & \textbf{0.909} & \textbf{0.913} \\
			\hline
		\end{tabular}
		\label{tab4}
	\end{center}
\end{table}



\section{在混合模式下的效果}
% =================================
% Fig. 03: Model architecture
% =================================
\begin{figure}[!htbp]
	\centering
	\includegraphics[width=0.80\textwidth]{AIBMF-confusematrix.png}
	\bicaption{AIBMF识别混淆矩阵}{AIBMF classification confusematrix}
	\label{fig:AIBMF_confusematrix}
\end{figure}


\section{小结}