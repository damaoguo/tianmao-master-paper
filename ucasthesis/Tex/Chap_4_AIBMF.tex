\chapter{基于多视图特征的移动应用识别方法}\label{chap:AIBMF}
HTTPS流量经过加密之后，传统的DPI方法已经不能够有效地完成识别任务。而传统地机器学习方法又需要大量地特征工程来提取特征，并且这些特征很容易受到网络环境的影响而不具备鲁棒性。本章将使用深度学习方法从HTTPS流量的多视图特征出发研究识别方法。

\section{引言}
本文中的分类/识别是指将HTTPS流量关联到产生它的应用上，是一个流量精细化识别和分类的方法。本文的研究工作是建立在对HTTPS流量以下三个方面的认知：

\emph{（i）} SSL/TLS协议本质上是移动应用客户端和服务器之间通信的一种语言，这种语言的具体表现是数据包序列；

\emph{（ii）}因为协议状态机是对网络流的总体抽象描述，所以可以从不同的协议状态信息中构造应用指纹。如消息类型，内容类型等协议定义的参数信息。

\emph {（iii）}尽管SSL/TLS隐藏了网络流的有效负载，但仍然从加密连接中泄漏可以用于流量识别的状态信息。

基于以上，采取深度学习的方法，从不同的视图特征进行研究，使用深度学习的方法提取抽象的特征，构建识别的模型。



\section{方法阐述}
本章提出了一种基于多视图特征的移动应用识别方法---\emph{AIBMF}\footnote{Mobile \underline{A}pplication \underline{I}dentification Over HTTPS Traffic \underline{B}ased on \underline{M}ulti-view \underline{F}eatures}，该方法的架构如图\ref{fig:AIBMF-Architecture}所示，由预处理，特征学习，流量识别三个步骤构成。在预处理时，从原始的流样本（pcap）文件中抽取识别视图；在特征学习时，针对识别视图使用深度学习方法提取抽象特征；在应用识别时，利用抽象特征完成精细化识别任务。
\begin{figure}[!htbp]
	\centering
	\includegraphics[width=0.80\textwidth]{AIBMF-model.pdf}
	\bicaption{AIBMF网络结构}{AIBMF Architecture}
	\label{fig:AIBMF-Architecture}
\end{figure}

\subsection{数据流预处理}
在数据集构建部分将流量数据按照流进行提取，形成的数据集中每一条流就是一个待识别的样本。 整个流的集合可以表示为
\begin{equation}
    D = \{{\{f_i\}}_{i=1}^{i=N}\}_{j=1}^{j=C} 
\end{equation}
这里$f_i$表示第$i$条流。如下从流量负载，内容类型部分和数据包大小三个部分提取原始视图。\textcolor{red}{各个字段的具体取值的含义}

%------------------------------------------------------------------------
\subsubsection{负载视图}
\textcolor{red}{图片的描述}
如图\ref{fig:wireshark-payload}所示，负载部分由ASCII码构成。
\begin{figure}[!htbp]
	\centering
	\includegraphics[width=0.35\textwidth]{Wireshark-payload.png}
	\bicaption{流量负载}{Payload}
	\label{fig:wireshark-payload}
\end{figure}
如下首先比较了饿了么、美团、今日头条和网易云音乐四款应用在负载的ASCII编码的分布情况。对于单个应用，将其所有流的所有包的负载按照字节的ASCII编码转换为0-255的数值，统计所有取值的数量，绘制散点图。
\begin{figure}[!htbp]
    \centering
    \begin{subfigure}[b]{0.35\textwidth}
      \includegraphics[width=\textwidth]{elem-payload.eps}
      \caption{}
      \label{fig:payload-elem}
    \end{subfigure}%
    ~% add desired spacing
    \begin{subfigure}[b]{0.35\textwidth}
      \includegraphics[width=\textwidth]{meituan-payload.eps}
      \caption{}
      \label{fig:payload-meituan}
    \end{subfigure}
    \\% line break
    \begin{subfigure}[b]{0.35\textwidth}
      \includegraphics[width=\textwidth]{jinritoutiao-payload.eps}
      \caption{}
      \label{fig:payload-jinritoutiao}
    \end{subfigure}%
    ~% add desired spacing
    \begin{subfigure}[b]{0.35\textwidth}
      \includegraphics[width=\textwidth]{cloudmusic-payload.eps}
      \caption{}
      \label{fig:payload-netease-cloud-music}
    \end{subfigure}
    \bicaption{流量负载字节分布。(a) 饿了么，(b) 美团，(c) 今日头条，(d) 网易云音乐。}{PAYLOAD.(a)Ele , (b)Meituan , (c)Jinritoutiao , (d)Netease-cloud-music.}
    \label{fig:payload-eda}
\end{figure}

如图\ref{fig:payload-eda}所示，图中横坐标表示的是ASCII编码的取值，纵轴为取值在这个应用所有的样本中所占的比例，可以发现针对不同的应用，负载的分布情况存在差异，为了更加进一步探索负载对于流量识别的作用，本文将其定义为PB视图。
%-------------------------------------------------------------------------
\subsubsection{内容类型视图}
内容类型（content type）是SSL/TLS协议定义的，取值范围及其意义见表\ref{tab:content-type}, 在HTTPS的通信过程中，其对于流中每一个数据包进行了标记。
\begin{table}[!htbp]
    \bicaption{内容类型。}{Content Type.}
    \label{tab:content-type}
    \centering
    \footnotesize% fontsize
    \setlength{\tabcolsep}{4pt}% column separation
    \renewcommand{\arraystretch}{1.2}%row space
    \resizebox{\columnwidth}{!}{
        \begin{tabular}{rccc}
        \textbf{取值} & \textbf{描述} & \textbf{DTLS-OJ} & \textbf{参考}\\
        \hline
        0-19 & Unassigned (Requires coordination; see [RFC7983]) & & [RFC5764][RFC7983]\\
        20 & change\_cipher\_spec & Y & [RFC8446]\\
        21 & alert & Y & [RFC8446]\\
        22 & handshake & Y & [RFC8446]\\
        23 & application\_data & Y & [RFC8446]\\
        24 & heartbeat & Y & [RFC6520]\\
        25 & tls12\_cid (TEMPORARY - registered 2019-07-02, expires 2020-07-02) & Y & [draft-ietf-tls-dtls-connection-id]\\
        26-63 & Unassigned & & \\
        64-255 & Unassigned (Requires coordination; see [RFC7983]) & & [RFC5764][RFC7983]\\
        \hline
        \end{tabular}    
    
    }

\end{table}
\textcolor{red}{图片的描述}
接着比较了饿了么、美团、今日头条和网易云音乐四款应用在内容类型（content type）的取值的分布情况，如图\ref{fig:content-type-eda}。计算了不同的content type取值在不同应用上的比例，得到分布情况。
\begin{figure}[!htbp]
    \centering
    \begin{subfigure}[b]{0.35\textwidth}
      \includegraphics[width=\textwidth]{elem-contenttype.eps}
      \caption{}
      \label{fig:oaspl_a}
    \end{subfigure}%
    ~% add desired spacing
    \begin{subfigure}[b]{0.35\textwidth}
      \includegraphics[width=\textwidth]{meituan-contenttype.eps}
      \caption{}
      \label{fig:oaspl_b}
    \end{subfigure}
    \\% line break
    \begin{subfigure}[b]{0.35\textwidth}
      \includegraphics[width=\textwidth]{jinritoutiao-contenttype.eps}
      \caption{}
      \label{fig:oaspl_c}
    \end{subfigure}%
    ~% add desired spacing
    \begin{subfigure}[b]{0.35\textwidth}
      \includegraphics[width=\textwidth]{cloudmusic-contenttype.eps}
      \caption{}
      \label{fig:oaspl_d}
    \end{subfigure}
    \bicaption{内容类型分布。(a) 饿了么，(b) 美团，(c) 今日头条，(d) 网易云音乐。}{PAYLOAD.(a)Ele , (b)Meituan , (c)Jinritoutiao , (d)Netease-cloud-music.}
    \label{fig:content-type-eda}
\end{figure}
为了更加进一步探索content type对于流量识别的作用，本文将其定义为CT视图。

%-----------------------------------------------------------------------
\subsubsection{数据包大小视图}
最后比较了饿了么、美团、今日头条和网易云音乐四款应用在数据包大小的分布情况。对于单个应用的所有样本流的所有数据包的大小进行统计。
\textcolor{red}{图片的描述}
\begin{figure}[!htbp]
    \centering
    \begin{subfigure}[b]{0.35\textwidth}
      \includegraphics[width=\textwidth]{elem-count.eps}
      \caption{}
      \label{fig:packet-size-ele}
    \end{subfigure}%
    ~% add desired spacing
    \begin{subfigure}[b]{0.35\textwidth}
      \includegraphics[width=\textwidth]{meituan-count.eps}
      \caption{}
      \label{fig:packet-size-meituan}
    \end{subfigure}
    \\% line break
    \begin{subfigure}[b]{0.35\textwidth}
      \includegraphics[width=\textwidth]{jinritoutiao-count.eps}
      \caption{}
      \label{fig:packet-size-jinritoutiao}
    \end{subfigure}%
    ~% add desired spacing
    \begin{subfigure}[b]{0.35\textwidth}
      \includegraphics[width=\textwidth]{cloudmusic-count.eps}
      \caption{}
      \label{fig:packet-size-netease-cloud-music}
    \end{subfigure}
    \bicaption{数据包大小分布。(a) 饿了么，(b) 美团，(c) 今日头条，(d) 网易云音乐。}{Packet Size.(a)Ele , (b)Meituan , (c)Jinritoutiao , (d)Netease-cloud-music.}
    \label{fig:packet-size-eda}
\end{figure}
如图\ref{fig:packet-size-eda}所示，不同的应用的数据包在大小上的分布存在显著的差异，为了更加进一步探索数据包大小对于流量识别的作用，本文将其定义为PS视图。


\subsubsection{视图特征矢量化}
由于已经有了流程对象，因此可以转向流程的数字矢量表示。

\emph{（i）}对于PS视图，通过计算前M个数据包的大小（用-1填充），形成了$ M $维矢量$ v_ {ps} $。

\emph{（ii）}对于CT视图，通过将值内容类型字段扩展为前M个数据包（用-1填充）来形成$ M $维矢量$ v_ {ct} $，其范围从0到255 。

\emph{（iii）}对于PB视图，通过将有效载荷字节值视为相应的ASCII码，对于每一个数据包取前N个字节，形成一个$ M \times N $维向量$v_{pb}$，然后进一步转换为0-255（ 用-1填充）。

以上涉及到的超参数M和N将再本章后面进行详细分析。


\subsection{多视图特征学习}
数据包有效载荷字节（PB）视图、数据包内容类型（CT）视图和针对数据包大小（PS）视图分别采用一维卷积神将网络、循环神经网络和一维卷积神经网络提取抽象的特征。

\begin{itemize}
	\item \textbf{PB视图特征学习} 
	%
	本章使用一维卷积神经网络处理 $v_{pb}$向量,如公式：\ref{eqn:1D-payload}。在处理过程中, 使用了两层卷积神经网络, 每一层卷积的卷积核数量是 64, 卷积核的大小是$1 \times 3$, 卷积操作中本章采用的是max pooling。经过处理后，原始的负载部分的转换为64维的向量 $\alpha$.
	%
	\begin{equation}
	\label{eqn:1D-payload}
		\alpha = \mathit{1\!D\!-\!C\!N\!N}(v_{pb})
	\end{equation}
	
	\item \textbf{CT视图特征学习} 
	Content Type 是一个用257维的one-hot编码的稀疏向量,每一个取值之间的距离为$\sqrt{2}$,one-hot夫人编码方式不能够有效表示上下文关系，所以本章引入了Embedding操作将这个257维的稀疏表示映射为一个16维的实数向量，这种表示方法有效保留了上下文关系。Embedding层需要学习一个转换向量，其大小为 $ (vocab\_size, embedding\_dim) $，Embedding基本上是一个矩阵，可以认为是从离散且稀疏的1热向量到连续且密集的潜在空间的转换。经过Embedding操作后，使用循环神经网络从CT视图序列特征中提取抽象特征，形式上如公式\ref{eqn:1D-content-type}所示。 
	\begin{equation}
	\label{eqn:1D-content-type}
		\gamma = \mathit{R\!N\!N}(Embedding(v_{ct}))
	\end{equation}
	
	经过RNN处理后，content type视图被转换为一个64维的向量$\gamma$
	
	\item \textbf{PS视图特征学习}
	%
	如公式：\ref{eqn:1D-packet-size}所示，$v_{ps}$向量和处理负载部分的一样，使用一维卷积神经网络进行处理, 所不同的是输入的向量大小为数据包的数目。
	%
	经过一维卷积神经网络的处理后, 数据包大小序列被转换为一个64维的向量 $\beta$.
	%
	\begin{equation}
	\label{eqn:1D-packet-size}
		\beta = \mathit{1D\!-\!C\!N\!N}(v_{ps})
	\end{equation}
	%

\end{itemize}


\subsection{应用识别}
如公式：\ref{eqn:feature-combine}所示，将三个不同的抽象特征连接在一起以形成192维向量，然后将其输入到完全连接的层。完全连接层的输出$ x $，将用作softmax回归的输入，以识别流量。
\begin{equation}
\label{eqn:feature-combine}
	\delta = \alpha \oplus \beta \oplus \gamma
\end{equation}
三种不同的抽象特征共同优化同一类别目标，共同计算多类交叉熵损失，并通过反向传播算法\citep{rumelhart1986learning}更新三个神经网络的参数。
%
从数学上讲，输出预测$ Y $是应用 $ a_j $的概率由公式：\ref{eqn:softmax}确定。
\begin{equation}
\label{eqn:softmax}
p(Y=j|x,W,b)=\mathit{softmax_j}(\emph{\textbf{W}}x + \emph{\textbf{b}})
% =\frac{e^{w_i^TZ+b_i}}{\sum_je^{w_j^TZ+b_j}}
\end{equation}

其中$ W $是完全连接层和softmax层之间的权重矩阵，而$ b $是偏移量。

如公式：\ref{eqn:argmax}所示，模型的预测值$y_{pd} $为概率最大的类别。
%
\begin{equation}
\label{eqn:argmax}
y_{pd}=argmax(p(Y=j|x,W,b)),\forall j \in \{1,2,3,...,C\}
\end{equation} 
%
AIBMF模型使用交叉熵 \citep{Boer2005A} 作为损失函数。

本文中所提到的研究识别模型的细节如表\ref{tab:AIBMF-layer}所示（此表是当超参数M=16，N=64时的情况）。
\begin{table}[!htbp]
    \bicaption{AIBMF网络}{AIBMF network.}
    \label{tab:AIBMF-layer}
    \centering
    \footnotesize% fontsize
    \setlength{\tabcolsep}{4pt}% column separation
    \renewcommand{\arraystretch}{1.2}%row space 
    \begin{tabular}{|c|c|c|c|}
        \hline
        \textbf{网络层(类型)} & \textbf{输出层} & \textbf{参数个数} & \textbf{上一层网络}\\
        \hline
        \hline
        packetPayload (InputLayer) & (None, 1024) & 0 & \\
        \hline
        packetSize (InputLayer) & (None, 16) & 0 & \\
        \hline
        batch\_normalization\_1 (BatchNor) & (None, 1024) & 4096 & packetPayload[0][0] \\
        \hline
        batch\_normalization\_2 (BatchNor) & (None, 16) & 64 & packetSize[0][0] \\     
        \hline
        reshape\_1 (Reshape) & (None, 1024, 1) & 0 & batch\_normalization\_1[0][0] \\
        \hline
        reshape\_2 (Reshape) & (None, 16, 1) & 0 & batch\_normalization\_2[0][0] \\
        \hline
        layer\_conv\_1 (Conv1D) & (None, 1022, 64) & 256 & reshape\_1[0][0] \\
        \hline
        layer\_conv\_3 (Conv1D) & (None, 14, 64) & 256 & reshape\_2[0][0] \\
        \hline
        max\_pooling1d\_1 (MaxPooling1D) &  (None, 1020, 64) & 0 & layer\_conv\_1[0][0] \\ 
        \hline
        max\_pooling1d\_3 (MaxPooling1D) & (None, 12, 64) & 0 & layer\_conv\_3[0][0] \\
        \hline
        layer\_conv\_2 (Conv1D) & (None, 1020, 32) & 6176 & max\_pooling1d\_1[0][0] \\  
        \hline
        recordTypes (InputLayer) & (None, 16) & 0 & \\     
        \hline
        layer\_conv\_4 (Conv1D) & (None, 12, 32) & 6176 & max\_pooling1d\_3[0][0] \\
        \hline
        max\_pooling1d\_2 (MaxPooling1D) & (None, 1018, 32) & 0 & layer\_conv\_2[0][0] \\
        \hline
        embedding\_1 (Embedding) & (None, 16, 32) & 8224 & recordTypes[0][0] \\
        \hline
        max\_pooling1d\_4 (MaxPooling1D) &  (None, 10, 32) & 0 & layer\_conv\_4[0][0] \\
        \hline
        flatten\_1 (Flatten) & (None, 32576) & 0 & max\_pooling1d\_2[0][0] \\
        \hline
        lstm\_1 (LSTM) & (None, 16) & 3136 & embedding\_1[0][0] \\
        \hline
        flatten\_2 (Flatten) & (None, 320) & 0 & max\_pooling1d\_4[0][0] \\ 
        \hline
        dense\_1 (Dense) & (None, 64) & 2084928 & flatten\_1[0][0] \\
        \hline
        dense\_2 (Dense) & (None, 64) & 1088 & lstm\_1[0][0] \\
        \hline
        dense\_3 (Dense) & (None, 64) & 20544 & flatten\_2[0][0] \\
        \hline
        concatenate\_1 (Concatenate) & (None, 192) & 0 & dense\_1[0][0],dense\_2[0][0],dense\_3[0][0] \\
        \hline
        main\_output (Dense) & (None, 20) & 3860 & concatenate\_1[0][0] \\
        \hline
        \hline
        \textbf{总共参数} & \multicolumn{3}{|c|}{2,138,804} \\
        \textbf{可训练的参数} & \multicolumn{3}{|c|}{2,136,724} \\
        \textbf{不可训练的参数} & \multicolumn{3}{|c|}{2,080} \\
        \hline
    \end{tabular}
\end{table}


\section{实验评估}
\subsection{评估指标}
为了对AIBMF在HTTPS流量数据上的识别性能进行合理有效的定量评估，本文介绍了一些基本指标：真阳性（True Positive, TP），假阴性（False Negative, FN），真阴性（True Negnative, TN）和假阳性（False Positive, FP）,如表~\ref{tab:confusion-matrix}所示，具体含义如下：
\begin{itemize}
    \item TP是分类为应用$ i $的流量确切属于应用$ i $的流的数量。
    \item FN是指属于应用$i$的流最终没有被识别为应用$i$的流的数量。
    \item TN是指不是应用$i$的流最终没有被识别为应用$i$的流的数量。
    \item FP是指不属于应用$i$的流最终被识别为应用$i$的流的数量。
\end{itemize}

\begin{table}[!htbp]
    \bicaption{识别结果的混淆矩阵。}{Confusion matrix of classification results.}
    \label{tab:confusion-matrix}
    \centering
    \footnotesize% fontsize
    \setlength{\tabcolsep}{4pt}% column separation
    \renewcommand{\arraystretch}{1.2}%row space 
    \begin{tabular}{l|l|c|c|c}
        \multicolumn{2}{c}{}&\multicolumn{2}{c}{\textbf{预测结果}}&\\
        \cline{3-4}
        \multicolumn{2}{c|}{} & \textbf{正类} & \textbf{负类} & \multicolumn{1}{c}{\textbf{总计}}\\
        \cline{2-4}
        \multirow{2}{*}{\textbf{真实情况}} & \textbf{正类} & 真正类(TP) & 假负类(FN) & $TP+FN$\\
        \cline{2-4}
        & \textbf{负类} & 假正类(FP) & 真负类(TN) & $FP+TN$\\
        \cline{2-4}
        \multicolumn{1}{c}{} & \multicolumn{1}{c} {\textbf{总计}} & \multicolumn{1}{c}{$TP+FP$} & \multicolumn{    1}{c}{$FN+TN$} & \multicolumn{1}{c}{$TP+FN+FP+TN$}\\
    \end{tabular}
\end{table}



在训练阶段，\emph{Accuracy（ACC）}用于指示模型识别能力的提高，并且改进了综合显示模型在识别HTTPS流量方面的性能。 准确率是在迭代训练过程中所有正确样本量与训练数据的比率，该比率是根据公式\ref{eqn:acc}计算的。

\begin{equation}
\label{eqn:acc}
ACC=\frac{TP+TN}{TP+TN+FP+FN}	
\end{equation}

在测试阶段，\emph{Precision（P）}显示预测到应用$ i $的流量是实际应用$ i $，\emph{Recall（R）}显示预测正确的流量与属于应用$i$的所有流的比值，以及HTTPS流量的综合评价\emph{F1}值用作评估标准。 \emph {P}根据公式（\ref{eqn:P}）计算； \emph {R}根据公式\ref{eqn:R}计算； F1值是结合两个指标的综合评价指标，是根据公式（\ref{eqn:F1}）计算的。 为了在所有$K$个应用上评估本文的方法，并将平均值$ P $，$ R $，$ F_1 $ --- $ Macro \ Precision $，$ Macro \ Recall $，$ Macro \ F_1 $作为整体指标 式（\ref{eqn:macro-P}），（\ref{eqn:macro-R}），（\ref{eqn:macro-F1}）。 


% ===========
% EQUATION:07
\begin{subequations}
	\begin{equation}
	\label{eqn:P}
	P=\frac{TP}{TP+FP}
	\end{equation}
	
	\begin{equation}
	\label{eqn:macro-P}
	Macro\ Precision=\frac{1}{K}\sum_{i=1}^{K}P_i
	\end{equation}
	
\end{subequations}

% ===========
% EQUATION:08
% ===========
\begin{subequations}
	\begin{equation}
	\label{eqn:R}
	R=\frac{TP}{TP+FN}	
	\end{equation}
	
	\begin{equation}
	\label{eqn:macro-R}
	Macro\ Recall=\frac{1}{K}\sum_{i=1}^{K}R_i
	\end{equation}
\end{subequations}


\begin{subequations}
	\begin{equation}
	\label{eqn:F1}
	F_1=2\frac{P\times R}{P+R}
	\end{equation}
	
	\begin{equation}
	\label{eqn:macro-F1}
	Macro\ F_1=\frac{1}{K}\sum_{i=1}^{K}F_{1i}
	\end{equation}
\end{subequations}


\subsection{实验环境和数据集划分}
\subsubsection{实验环境}
本文所需的实验环境见表~\ref{tab:experiment-enviorment}。
\begin{table}[!htbp]
    \bicaption{实验所需的软硬件环境。}{Hardware and software environment of experiments.}
    \label{tab:experiment-enviorment}
    \centering
    \footnotesize% fontsize
    \setlength{\tabcolsep}{4pt}% column separation
    \renewcommand{\arraystretch}{1.2}%row space 
    \begin{tabular}{lcc}
        \hline
        \multirow{3}{*}{硬件} & CPU & 24 Intel (R) Xeon CPU E5-2650 v4 @ 2.2GHz \\
        & GPU & 2 GTX TITAN X \\
        & RAM & 128GB\\
        \hline
        \multirow{5}{*}{软件} & 操作系统 & Ubuntu 16.04 LTS\\
        & 编程语言 & Python 3.6, Linux bash \\
        & 深度学习框架 & Tensorflow 1.12，Keras 2.2.4\\
        & 机器学习框架 & scikit-learn 0.22.1\footnotemark[1]\\
        & 重要Python包 & Scapy\footnotemark[2], Pandas\footnotemark[3], Numpy\footnotemark[4], Matplotlib\footnotemark[5] \\
        \hline
    \end{tabular}

\end{table}
\footnotetext[1]{https://scikit-learn.org/}
\footnotetext[2]{https://scapy.net/}
\footnotetext[3]{https://pandas.pydata.org/}
\footnotetext[4]{https://numpy.org/}
\footnotetext[5]{https://matplotlib.org/}

\subsubsection{数据集划分}
本章针对所采集的前20个应用共计10,000多条样本进行训练和识别，将100,000多个带有标签的样本分为两个部分：训练集和测试集。为了确保随机性，对数据进行了随机操作，其中训练集占90％，测试集占10％。


\subsection{敏感性参数分析}

\subsubsection{参数M的确定}
针对前20个应用100,000多个流数据，并研究了各种应用的数据包计数分布。如图\ref{fig:packet-count-all}所示，超过100,000个流的数据包计数的中位数为11，一个流中的数据包计数超过16只占32％，针对每一条流，取用不同的数据包的数目进行对比实验,如图\ref{fig:packet-count-acc}，发现，随着数据包的数目的增加，模型的识别效果也在持续增加，当数据包的数目增加为16个的时候，识别的效果不再由明显的变化，但是经过分析，随着数据包数目的增加，模型所需要的空间复杂度和时间复杂度都会增加。在这里，将数据包的数目取为16.

\begin{figure}[!htbp]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
      \includegraphics[width=\textwidth]{Packet-count-all.eps}
      \caption{}
      \label{fig:packet-count-all}
    \end{subfigure}%
    ~% add desired spacing
    \begin{subfigure}[b]{0.45\textwidth}
      \includegraphics[width=\textwidth]{Payload-size-acc.eps}
      \caption{}
      \label{fig:packet-count-acc}
    \end{subfigure}
    ~% add desired spacing

    \bicaption{超参数M。(a)流中数据包数统计 ，(b) 不同数据包数量识别效果。}{Parameter M.(a)Statistics in  Packet Count, (b)Performance of Different M .}
    \label{fig:oaspl}
\end{figure}


\subsubsection{参数N的确定}
为了确定每个数据包使用多少字节，进行了一系列比较实验。如图\ref{fig:payload-size}所示，每个数据包以不同的长度截取，随着截取长度的增加，1D-CNN的识别能力增强。 当采用前64个字节时，测试集的准确性为93.34％。在64个字节的长度之后，精度会非常缓慢地增加，并且增益随着长度的增加而降低，但是1D-CNN的时间复杂度和空间复杂度将显着增加，因此每个数据包的长度设置为64。

\begin{figure}[!htbp]
	\centering
	\includegraphics[width=0.45\textwidth]{Packet-count-acc.eps}
	\bicaption{超参数N}{Parameter N}
	\label{fig:payload-size}
\end{figure}

\subsection{不同深度学习模型方法对比}
在实验的过程种，如图\ref{fig:performance-dl}，分别比较了仅仅使用一维卷积神经网络、二维卷积神经网络处理负载视图和AIBMF模型训练的过程，对比了在识别的过程中，loss和accuracy的变化过程。发现在训练的过程中，AIBMF模型损失下降更快，即更快收敛，准确率也领先其他的深度学习模型。
\begin{figure}[!htbp]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
      \includegraphics[width=\textwidth]{AIBMF-training-loss.png}
      \caption{}
      \label{fig:acc-training}
    \end{subfigure}%
    ~% add desired spacing
    \begin{subfigure}[b]{0.45\textwidth}
      \includegraphics[width=\textwidth]{AIBMF-training-acc.png}
      \caption{}
      \label{fig:loss-training}
    \end{subfigure}
    ~% add desired spacing

    \bicaption{不同深度学习模型表现。(a) 准确率变化，(b) 损失变化。}{Performance of Different DL model (a) Accuracy over Training, (b) Loss over Training.}
    \label{fig:performance-dl}
\end{figure}



\subsection{基于流统计特征的方法}
本文的研究工作还对比了机器学习的方法，首先使用特征工程的方法构建了23种特征，见表\ref{tab:statistical-feature}，其中7种特征是HTTPS协议相关的，其余的16种特征是流量分析工作常用的特征，属于协议无关的特征。

\begin{longtable}{ccc}
    \bicaption{统计特征。}{Statistical Feature.}\\
	\hline
	\textbf{统计特征} & \textbf{含义} & \textbf{是否协议相关？} \\
	\hline
	\endfirsthead
	\multicolumn{3}{c}%
        {\bfseries\small \tablename\ \thetable\ {续表。}}\\
	\hline
	\textbf{统计特征} & \textbf{含义} & \textbf{是否协议相关？} \\
	\hline
	\endhead
	\hline \multicolumn{3}{r}{\textit{续表见下页}}\\
	\endfoot
	\hline
	\endlastfoot
	Packet counts & 数据包个数& 否\\
	TTL max & TTL最大值 & 否\\
	TTL min & TTL最小值 & 否\\
	TTL mean & TTL平均值 & 否\\
	TTL median & TTL中位数 & 否\\
	TTL var & TTL方差 & 否\\
	packet\_length max & 数据包长度最大值 & 否\\
	packet\_length min & 数据包长度最小值 & 否\\
	packet\_length mean & 数据包长度平均值 & 否\\
	packet\_length median & 数据包长度中位数 & 否\\
	packet\_length var & 数据包长度方差 & 否\\
	window max & 窗口最大值 & 否\\
	window min & 窗口最小值 & 否\\
	window mean & 窗口平均值 & 否\\
	window median & 窗口中位数 & 否\\
	window var & 窗口方差 & 否\\
	session\_id\_length max & session id长度 & 否\\
	client\_extensions\_length max & client extensions长度最大值 & 是\\
	client\_extensions\_length min & client extensions长度最小值 & 是\\
	client\_extensions\_length mean & client extensions长度平均值 & 是\\
	client\_extensions\_length median & client extensions长度中位数 & 是\\
	client\_extensions\_length var & client extensions长度方差 & 是\\
	client\_ciphers counts & 客户端加密组件种类 & 是\\
	server\_cipher & 服务端加密组建类型 & 是\\
	\hline
	\label{tab:statistical-feature}
\end{longtable}
针对提取的23种特征，分别使用了随机森林，支持向量机和单层神经网络进行训练和识别，和本章提出的AIBMF模型相比较，基于机器学习的方法在识别能力弱。如表\ref{tab:ml-performance}所示，AIBMF模型在三个参数上均领先于其他的识别模型。

\begin{table}[!htbp]
    \bicaption{机器学习和AIBMF识别效果对比。}{Comparation the Performance between ML and AIBMF.}
    \label{tab:ml-performance}
    \centering
    \footnotesize% fontsize
    \setlength{\tabcolsep}{4pt}% column separation
    \renewcommand{\arraystretch}{1.2}%row space 
	\begin{tabular}{ c  c  c  c }
		\hline
		\textbf{机器学习算法} & \textbf{宏精度} & \textbf{宏召回率} & \textbf{宏F1} \\
		\hline
		随机森林 & 0.8805 & 0.8172 & 0.8407 \\
		支持向量机 & 0.9214 & 0.5754 & 0.6676 \\
		DNN & 0.7362 & 0.6293 & 0.6562 \\
		\textbf{AIBMF} & \textbf{0.918} & \textbf{0.909} & \textbf{0.913} \\
		\hline
	\end{tabular}
\end{table}


\subsection{AIBMF模型识别效果}
如图\ref{fig:Performance-AIBMF-Baseline}所示，在本章使用的前20个应用的数据集上将AIBMF与\citet{Wang2017End}的工作进行了比较。 评估结果表明，AIBMF在精度，召回率和F1得分方面至少优于2.0％。
\begin{figure}[!htbp]
	\centering
	\includegraphics[width=0.6\textwidth]{Performance-AIBMF-Baseline.eps}
	\bicaption{AIBMF模型和Baseline的比较}{AIBMF vs. Baseline.}
	\label{fig:Performance-AIBMF-Baseline}
\end{figure}


如图\ref{fig:AIBMF-confusematrix}，针对20个移动应用1万条测试样本，绘制混淆矩阵来观察识别的效果。整体上，识别的效果非常好，其中大多数的错误是由于不同的应用之间可能共享服务所致，尤其针对那些由同一个公司开发的应用而言，识别能力存在一定的混淆。有一些应用将其API提供给了其他的应用作为公共接口，如百度地图，这给AIBMF模型的识别能力带来了一定的影响。另外在实验中，QQ软件的识别效果最差。 可能的原因是QQ使用的通信协议主要是UDP，并补充了TCP协议。第三章捕获的流量主要从Qzone捕获，该流量混合了许多其他应用的流量。





\begin{figure}[!htbp]
	\centering
	\includegraphics[width=0.6\textwidth]{AIBMF-confusematrix.png}
	\bicaption{AIBMF识别混淆矩阵}{AIBMF classification confusematrix}
	\label{fig:AIBMF-confusematrix}
\end{figure}


\section{本章小结}
人工定义的统计特征越复杂，流量识别任务的通用性就越差。但是，仅使用深度学习忽略协议设计的信息来处理有效负载，识别能力也受到限制。实际上，协议定义的一些有意义的信息（例如内容类型）提取代价很低，在流量分析中却很有用。因此，从多个角度分析HTTPS流量并组合不同的功能可能是将来加密流量分析中的有力选择。本章节提出了一种通过HTTPS流量进行应用识别的方法---AIBMF。该方法能够分析HTTPS应用流量并将HTTPS流量与特定的移动应用相关联。