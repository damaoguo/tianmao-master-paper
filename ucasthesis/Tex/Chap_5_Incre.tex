\chapter{基于增量学习的HTTPS新应用识别}\label{chap:transfer}
\section{引言}

\section{迁移学习方法}

\section{增量学习方法}

\subsection{增量学习框架}
\begin{figure}[!htbp]
	\centering
	\includegraphics[width=0.80\textwidth]{IncreAIBMF.pdf}
	\bicaption{IncreAIBMF架构}{IncreAIBMF architecture}
	\label{fig:IncreAIBMF architecture}
\end{figure}



\subsubsection{构建训练集}
此阶段准备训练数据以用于下一个训练阶段。训练集由旧类的代表性样本的一部分（代表存储器中存储的旧类的示例）和新的app类的样本组成。由于我们的方法使用了两个损失函数，即分类和蒸馏，因此每个样本都需要两个标签，与这两个损失相关联。为了进行分类，我们使用一键向量来指示应用程序出现在所有应用程序类中。对于蒸馏，我们使用每个识别模块使用旧的应用程序类生成的蒸馏标签。因此，每个样品的蒸馏标签与具有旧应用程序类的识别模块一样多。为了更好地理解，我们在哪里执行IncreAIBMF的第三步增量。此时，两个标识模块将在旧应用程序上运行，一个标识模块将处理新应用程序。对样品进行评估时，将使用旧应用程序的两个识别模块生成的蒸馏标签用于蒸馏，将使用三个识别模块生成的蒸馏标签用于分类。


\subsubsection{训练过程}
训练阶段将带有相应标签的增强训练集作为交叉蒸馏损失计算的输入，并更新整个网络体系结构的所有参数。 交叉蒸馏损失函数L（！）定义为：
\begin{equation}
	\label{eq:cdl}
	L(\omega)=L_{C}(\omega)+\lambda\sum_{f=1}^{F} L_{D_{f}}(\omega)
\end{equation}

where $L_{C}(\omega)$ is the cross-entropy loss applied to samples from the old and new classes. 
%
$L_{D_{f}}$is the distillation loss of the classification layer $f$, and $F$ is the total number of classification layer for the old apps. 
%
$\lambda$ is refered to ratio that distilled loss in the cross-distilled loss. In our training process, we set it 0.3. 
%
The cross-entropy loss $L_{C}(\omega)$ is given by:
%
\begin{equation}
	L_{C}(\omega)=-\frac{1}{N} \sum_{i=1}^{N} \sum_{j=1}^{C} p_{i j} \log q_{i j}
\end{equation}
%
where $qi$ is a score obtained by applying a softmax function to the logits of a classification layer for sample $i$, $pi$ is the ground truth for the sample $i$, and $N$ and $C$ denote the number of samples and classes respectively.
%
The distillation loss $L_{D}(\omega)$ is defined as:
%
\begin{equation}
	L_{D}(\omega)=-\frac{1}{N} \sum_{i=1}^{N} \sum_{j=1}^{C} { pdist }_{i j} \log {qd i s t}_{i j}
\end{equation}
%
where $pdisti$ and $qdisti$ are modified versions of $pi$ and $qi$, respectively. 

\subsubsection{代表性空间更新}
%
The goal of this phase is to update the sample in the memory, and ensure that the size of the training set does not increase dramatically.
%
That is, in the updated memory, we fixed the memory size to $K$ flows ($K=100,000$ in this paper), and the number of samples corresponding to each category of application is $\frac{100,000}{C}$, here $C$ indicates the category of the application. 
%
Then, we employ the two operations:
%
\emph{(i)} selection of new samples to store: we perform the herding selection strategy \cite{welling2009herding}, which produces a sorted list of samples of one class based on the distance to the mean sample of that class;
%
Given the sorted list of samples, the first $n$ samples of the list are selected. 
%
These samples are most representative of the class according to the mean.
%
% This step is performed after the training process to allocate memory for the samples from the new classes.
%
\emph{(ii)} removal of leftover samples: as the samples are stored in a sorted list, this operation is trivial.
%
The memory unit only needs to remove samples from the end of the sample set of each class. 
%
Note that after this operation, the removed samples are never used again.




\subsection{实验和评估}

\subsubsection{全量数据训练}

\subsubsection{迁移学习效果}

\begin{figure}[!htbp]
	\centering
	\includegraphics[width=0.90\textwidth]{AIBMF-Fine-tuning.pdf}
	\bicaption{AIBMF 微调}{AIBMF Fine tuning}
	\label{fig:AIBMF-Fine-tuning}
\end{figure}

\subsubsection{增量学习表现}



\begin{figure}[!htbp]
	\centering
	\includegraphics[width=0.90\textwidth]{Incre-confuse-matrix.pdf}
	\bicaption{IncreAIBM 混淆矩阵}{IncreAIBM confuse matrix}
	\label{fig:IncreAIBM confuse matrix}
\end{figure}


\begin{figure}[!htbp]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
      \includegraphics[width=\textwidth]{Full-comparation.eps}
      \caption{}
      \label{fig:oaspl_a}
    \end{subfigure}%
    ~% add desired spacing
    \begin{subfigure}[b]{0.45\textwidth}
      \includegraphics[width=\textwidth]{Incre-comparation.eps}
      \caption{}
      \label{fig:oaspl_b}
    \end{subfigure}
    ~% add desired spacing

    \bicaption{总声压级。(a) 这是子图说明信息，(b) 这是子图说明信息。}{OASPL.(a) This is the explanation of subfig, (b) This is the explanation of subfig.}
    \label{fig:oaspl}
\end{figure}

\begin{figure}[!htbp]
	\centering
	\includegraphics[width=0.90\textwidth]{Time-cost-incre.eps}
	\bicaption{AIBMF和IncreAIBM时间消耗对比 }{Time cost comparation between AIBMF and IncreAIBMF}
	\label{fig:Time-cost-incre}
\end{figure}


\section{小节}
