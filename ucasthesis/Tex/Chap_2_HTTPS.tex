\chapter{相关概念及技术}\label{chap:https}
本章详细介绍了论文所涉及到的理论知识，首先介绍HTTPS协议相关基础知识。然后针对本文中涉及到的机器学习、深度学习、增量学习方法总结。

\section{HTTPS简介}
HTTPS (Secure Hypertext Transfer Protocol)安全超文本传输协议，是一个安全通信通道，它基于HTTP开发用于在客户计算机和服务器之间交换信息。它使用安全套接字层(SSL)进行信息交换，简单来说它是HTTP的安全版,是使用TLS/SSL加密的HTTP协议。HTTP协议采用明文传输信息，存在信息窃听、信息篡改和信息劫持的风险，而协议TLS/SSL具有身份验证、信息加密和完整性校验的功能，可以避免此类问题发生。它是介于TCP和HTTP之间的一层安全协议，不影响原有的TCP协议和HTTP协议，所以使用HTTPS基本上不需要对HTTP页面进行太多的改造。HTTPS，HTTP以及TLS/SSL的关系如图\ref{fig:https-http}，在本章中对TLS/SSL协议的分析即为针对HTTPS协议的分析。

\begin{figure}[!htbp]
	\centering
	\includegraphics[width=0.45\textwidth]{HTTPS-HTTP.pdf}
	\bicaption{HTTPS,HTTPS和TLS/SSL的关系 }{Relationship between HTTPS, HTTPS and TLS/SSL}
	\label{fig:https-http}
\end{figure}



\section{HTTPS加密的理论基础}
HTTPS加密通信功能实现主要是依赖于三类基本的算法：非对称加密、对称加密以及散列算法。非对称加密主要用于密钥协商的阶段，非对称加密和解密的过程比较困难，因为这涉及到求解最大素数。对称加密重要用于密钥协商好之后的加密通信，这个密钥主要是client发起的（ 即客户端产生的Pre-master，于是，客户端和服务端之间的通信是一对一的加密通信），在这个过程中，多次使用了hash算法，hash算法将不同长度的信息计算为等长的信息，这个过程是不可逆的，目的是为了验证数据的完整性，对称加密过程相对于非对称加密要简单，在HTTPS握手过程中首先使用的非对称加密协商出了对称加密的私钥。针对三类算法的介绍如下：
\begin{itemize}
    \item 非对称加密：即常见的 RSA 算法，还包括 ECC、DH 等算法\citep{结城浩2015图解密码技术}，算法特点是，密钥成对出现，一般称为公钥(公开)和私钥(保密)，公钥加密的信息只能私钥解开，私钥加密的信息只能公钥解开。因此掌握公钥的不同客户端之间不能互相解密信息，只能和掌握私钥的服务器进行加密通信，服务器可以实现1对多的通信，客户端也可以用来验证掌握私钥的服务器身份。非对称加密的特点是信息传输1对多，服务器只需要维持一个私钥就能够和多个客户端进行加密通信，但服务器发出的信息能够被所有的客户端解密，且该算法的计算复杂，加密速度慢。它需要两个密钥，一个是公开密钥，另一个是私有密钥；公钥用作加密，私钥则用作解密。使用公钥把明文加密后所得的密文，只能用相对应的私钥才能解密并得到原本的明文，最初用来加密的公钥不能用作解密。由于加密和解密需要两个不同的密钥，故被称为非对称加密；不同于加密和解密都使用同一个密钥的对称加密。公钥可以公开，可任意向外发布；私钥不可以公开，
    
    \item 对称加密：常见的有AES-CBC、DES、3DES、AES-GCM等\citep{结城浩2015图解密码技术}，相同的密钥可以用于信息的加密和解密，掌握密钥才能获取信息，能够防止信息窃听，通信方式是1对1;对称加密的优势是信息传输1对1，需要共享相同的密码，密码的安全是保证信息安全的基础，服务器和 N 个客户端通信，需要维持 N 个密码记录，且缺少修改密码的机制。
    
    \item 散列算法：常见的有MD5、SHA1、SHA256\citep{结城浩2015图解密码技术}，该类函数特点是函数单向不可逆、对输入非常敏感、输出长度固定和输入的长度无关，针对数据的任何修改都会改变散列函数的结果，这种性质称为抗碰撞性(collision resistance)，用于防止信息篡改并验证数据的完整性;在信息传输过程中，散列函数不能单独实现信息防篡改，因为明文传输，中间人可以修改信息之后重新计算信息摘要，因此需要对传输的信息以及信息摘要进行加密;

\end{itemize}



\section{HTTPS安全机制}
\subsection{HTTPS连接建立的过程}
一个完整的 HTTPS 链接的建立大概需四步，假设 DNS 的查询时间忽略不计，那么从开始到建立一个完整的 HTTPS 连接大概一共需要 4 个RTT（往返时延，Round-Trip Time），如果是浏览刚刚已经访问过的站点的话，通过 TLS 的会话恢复机制，第三步 TLS 握手能够从 2 RTT变为 1 RTT。
\begin{itemize}
	\item \textbf{DNS 查询：}浏览器在建立链接之前，需要将域名转换为互联网 IP 地址。一般默认是由ISP DNS提供解析。ISP 通常都会有缓存的，一般来说花费在这部分的时间很少。
	\item \textbf{TCP 握手(1 RTT )}和服务器建立 TCP 连接，客户端向服务器发送 SYN 包，服务端返回确认的 ACK 包，这会花费一个往返(1 RTT)。
	\item \textbf{TLS 握手(2 RTT)：}该部分客户端会和服务器交换密钥，同时设置加密链接，对于 TLS 1.2 或者更早的版本，这步需要 2 个 RTT。
	\item \textbf{建立 HTTP 连接(1 RTT)：}一旦 TLS 连接建立，浏览器就会通过该连接发送加密过的 HTTP 请求。
\end{itemize}

\subsection{HTTPS握手过程}
图\ref{fig:https-handshake}表示的是HTTPS的握手过程。
\begin{figure}[!htbp]
	\centering
	\includegraphics[width=0.90\textwidth]{HTTPS-handshake.pdf}
	\bicaption{HTTTPS握手过程}{HTTPS handshake}
	\label{fig:https-handshake}
\end{figure}

\begin{itemize}
    % https://segmentfault.com/a/1190000016636897
	\item \textbf{client hello：}客户端首先主动发起请求，以明文传输请求信息：包括版本信息，加密套件候选列表，压缩算法候选列表，随机数，扩展字段信息。相关信息如下：
	
	\begin{itemize}
	    \item 版本信息：SSL 1.0没用公开使用；SSL 2.0于1995发布，2011年被弃用（参考RFC 6176）；SSL 3.0于1996年发布，2011年被废弃（参考RFC 7568）；TLS 1.0于1999年发布，计划2020年弃用，TLS 1.1	于2006年发布，计划2020年弃用\citet{bright2018apple}；TLS 1.2于2008年发布；TLS 1.3于2018年发布。	
	    \item 客户端的加密套件ciphersuites列表：每个加密套件对应着四个主要的功能组合---认证算法AU（身份验证）、密钥交换算法keyExchange密钥协商、对称加密算法Enc信息加密、和信息摘要Mac信息完整性校验。
	    \item 支持的压缩算法列表：用于后续的压缩计算\citep{hollenbeck2004transport}。
	    \item 随机数：用于后续的密钥生成。
	    \item 扩展字段信息：TLS/SSL扩展信息包括了server\_name, max\_fragment\_length, client\_certificate\_url, trusted\_ca\_keys,  truncated\_hmac,   status\_request等信息\citep{blake2003transport, eastlake2011transport}。其中SNI(Server Name Indication)定义在RFC 4366\citep{blake2003transport}中，是一项用于改善SSL/TLS的技术，在SSL3.0/TLS1.0中被启用,其在流量的精细化识别的工业应用中很常见。它允许客户端在发起SSL握手请求时(具体说来，是客户端发出SSL请求中的ClientHello阶段)，就提交请求的Host信息，使得服务器能够切换到正确的域并返回相应的证书。早期的SSL2.0根据经典的公钥基础设施PKI(Public Key Infrastructure)设计，它默认认为：一台服务器(或者说一个IP)只会提供一个服务，所以在SSL握手时，服务器端可以确信客户端申请的是哪张证书。在HTTP协议中，请求的域名作为主机头(Host)放在HTTP Header中，所以服务器端知道应该把请求引向哪个域名，但是早期的SSL做不到这一点，因为在SSL握手的过程中，根本不会有Host的信息，所以服务器端通常返回的是配置中的第一个可用证书。因而一些较老的环境，可能会产生多域名分别配好了证书，但返回的始终是同一个。既然问题的原因是在SSL握手时缺少主机头信息，那么补上就是了，即添加扩展。
	\end{itemize}
	
	\item \textbf{server hello + server certificate + server hello done：}
	\begin{itemize}
	    \item server hello服务器返回协商的信息，主要和client hello比较类似，区别在于服务器端对于cipher suite进行了选择，压缩算法进行了选择；
	    \item server certificate 服务器端配置对应的证书链，用于身份验证和密钥交换；
	    \item server hello done，通知客户端server hello信息发送结束。这个过程也是通过明文进行传输的，通过抓包，可以获取到加密套件cipher suite.server hello done通知客户端srver hello信息发送结束。
	\end{itemize}
	
	\item \textbf{客户端验证证书的合法性：}证书是第三方机构提供的，采用证书的原因在于公开加密还存在一些问题就是无法证明公开秘钥的正确性，为了解决这个问题，HTTPS采取了有数字证实认证机构和其相关机构颁发的公开秘钥证书。在客户端：如浏览器中保存了相关的证书信息，如果证书通过才会进行后续的通信，否则根据错误的信息提示操作。合法性的检验包括：证书链的可信性，证书是否被吊销，有效期以及域名。
	
	\item \textbf{client key exchange + change cipher spec:}合法性验证通过后客户端计算随机产生Pre-master，使用公钥加密，发送给服务器，此时此刻，客户端实际已经计算出协商密钥了，用到的信息是之前产生的。通过计算协商密钥，change\_cipher\_spec客户端通知服务器后续的通信都是通过协商密钥对称加密的方式进行。encrypted handshake messge,结合之前使用到的所有通信参数的hash值与其他的相关信息生成一段数据，采用协商密钥session secret与算法进行加密，然后发送服务器用于数据与握手验证。
	\begin{equation}
		enc\_key=Fuc(random\_C,random\_S,Pre\-master)
	\end{equation}
	
	\item \textbf{change cipher spec + encrypted handshake messege:}服务器用私钥解密加密的Pre-master，基于之前的random\_C和random\_S计算得到协商密钥, 计算之前所有接受信息的hash值，然后解密客户端发送的encrypted handshake messege，验证数据和密钥的正确性。之后，change cipher spec，验证通过以后，服务器也要发送change cipher spec以告知客户端后期的通信都是采用协商的密钥与算法进行通信。然后是encrypted handshake messege阶段，服务器也将结合当前通信参数信息生成一段数据并采用协商密钥session secret与算法加密发送给客户端。
	\item \textbf{握手结束：}客户端计算接收到的数据的hash值，采用协商好的密钥解密服务器发送过来的encrypted handshake messege验证服务器发送的数据和密钥，验证通过则握手结束。
	\item \textbf{加密通信:}开始使用协商的密钥与算法进行加密通信。
\end{itemize}

% \subsection{SSL加密计算过程}
% SSL加密计算过程为：

% \begin{figure}[!htbp]
% 	\centering
% 	\includegraphics[width=0.60\textwidth]{ssl_encrypted}
% 	\bicaption{SSL加密计算 }{}
% 	\label{fig:SSL_encrypted}
% \end{figure}

% Pre-master由客户端产生，采用RSA或Diffie-Hellman等加密算法生成，Pre-master结合random client和random server两个随机数通过PseudoRandomFunction(PRF)计算得到Master secret，Master secret结合两个随机数进行迭代计算得到Key material.


\section{相关机器学习/深度学习算法}
\subsection{常用的机器学习算法}
\begin{itemize}
    \item \textbf{随机森林：}在机器学习中，随机森林是一个包含多个决策树的分类器最早由\citep{breiman2001random}提出。随机森林是以决策树为基础的一种更高级的算法，并且其输出的类别是由个别树输出的类别的众数而定。目前，针对各个主流语言都有随机森林的实现\footnote{http://www.stat.berkeley.edu/~breiman/RandomForests/cc\_software.htm}\footnote{http://www.alglib.net/dataanalysis/decisionforest.php}\footnote{http://cran.r-project.org/web/packages/randomForest/index.html}\footnote{https://code.google.com/p/randomforest-matlab}\footnote{http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html}。
    
    \item \textbf{支持向量机：}在机器学习中，支持向量机（英语：support vector machine，常简称为SVM）是在分类与回归分析中分析数据的监督式学习模型与相关的学习算法。给定一组训练实例，每个训练实例被标记为属于两个类别中的一个或另一个，SVM训练算法创建一个将新的实例分配给两个类别之一的模型，使其成为非概率二元线性分类器。对于支持向量机来说，数据点被视为 p 维向量。
    
    % \item \textbf{隐马尔科夫模型：},目前重要的实现包括：seqlearn\footnote{https://github.com/larsmans/seqlearn}和HTK\footnote{http://htk.eng.cam.ac.uk/}。
    
\end{itemize}


\subsection{常用深度学习算法}
深度学习算法尝试通过使用多层层次结构来学习（多个级别的）表示形式。近年来，其在图像处理\citep{krizhevsky2012imagenet, taigman2014deepface}，语音识别\citep{ping2017deep,xiong2016achieving}，自然语言处理\citep{gehring2017convolutional,zhang2015character}等领域均取得了良好的效果。下面主要介绍卷积神经网络和循环神经网络，本文基于这两个深度学习结构设计了特征提取和识别模型。
\begin{itemize}
    \item \textbf{卷积神经网络}卷积神经网路（Convolutional Neural Network, CNN）是一种前馈神经网络，在图像和语音识别方面能够给出更好的结果,它的人工神经元可以响应一部分覆盖范围内的周围单元，对于大型图像处理有出色表现。卷积神经网路由一个或多个卷积层和顶端的全连通层（对应经典的神经网路）组成，同时也包括关联权重和池化层（pooling layer）。典型的卷积网络包含三个阶段\citep{goodfellow2016deep}。
    \begin{itemize}
        \item 在第一阶段，该层并行执行几个卷积以产生一组线性激活。
        \item 在第二阶段，每个线性激活都是通过非线性激活函数进行的。
        \item 在第三阶段，使用池化操作进一步修改图层的输出。合并功能使用某个位置处相邻输出的统计特性来替换该位置处的网络输出
    \end{itemize}
    
    对于时间序列数据，它可以被认为是以一定时间间隔采样的一维网格，对于图像数据，其可以被认为是二维像素网格。卷积神经网络表示网络采用称为卷积的数学运算,如图\ref{fig:CNN_2D}是二维卷积神经网络的结构图，二位卷积神经网络用于学习空间特征，尤其在图像领域取得了优秀的效果, 对于二维图像,输入为I，二维内核K, 卷积的计算过程如公式\ref{eqn:cnn-operation}：
    \begin{equation}
    \label{eqn:cnn-operation}
        S(i,j)=(I*K)(i,j)=\sum_{m}\sum_{n}I(m,n)K(i-m,j-n)
    \end{equation}
    
    如图\ref{fig:CNN_1D}是一维卷积神经网络的结构图，一维卷积神经网络常用于学习序列特征，在很多场景中其性能已经得到了验证：\citet{kim2014convolutional}使用一维卷积神经网络完成了句子分类任务。 
    \begin{figure}[!htbp]
        \centering
        \begin{subfigure}[b]{0.45\textwidth}
          \includegraphics[width=\textwidth]{CNN2D.pdf}
          \caption{}
          \label{fig:CNN_2D}
        \end{subfigure}%
        % \\% line break
        ~% add desired spacing
        \begin{subfigure}[b]{0.45\textwidth}
          \includegraphics[width=\textwidth]{CNN1D.pdf}
          \caption{}
          \label{fig:CNN_1D}
        \end{subfigure}
        ~% add desired spacing
    
        \bicaption{卷积神经网络。(a) 二维卷积神经网络，(b) 一维卷积神经网络。}{CNN.(a)2D convolutional neural network , (b) 1D convolutional neural network.}
        \label{fig:CNN}
    \end{figure}
    
    
    
    
    \item \textbf{循环神经网络} 
    如图\ref{fig:simple-rnn}所示为Hidden Layer的层级展开图。 
    $t-1, t, t+1$表示时间序列, $X$表示输入的样本。 $S_t$表示样本在时间$t$处的的记忆,$S_t = f(W*St-1 +U*X_t)$，其中$W$表示输入的权重,其中,$f$和$g$均为激活函数。其中$f$可以是$tanh,relu,sigmoid$等激活函数，$g$通常是$softmax$，当然也可以是其他激活函数。这里的$W,U,V$在每个时刻都是相等的(权重共享)。$U$表示此刻输入的样本的权重,$V$表示输出的样本权重.单纯的RNN因为无法处理随着递归，权重指数级爆炸或梯度消失问题，难以捕捉长期时间关联；而结合不同的LSTM可以很好解决这个问题\citep{hochreiter1997long}。
    
    如图\ref{fig:lstm}，LSTM可以通过“门”结构来去除或者增加“细胞状态”的信息,实现了对重要内容的保留和对不重要内容的去除.通过Sigmoid层输出一个0到1之间的概率值，描述每个部分有多少量可以通过，0表示“不允许任务变量通过”，1表示“运行所有变量通过 ”。用于遗忘的门叫做"遗忘门"（见图\ref{fig:simple-rnn}的$f$），用于信息增加的叫做"信息增加门"，（见图\ref{fig:simple-rnn}的$i$），最后是用于输出的"输出门"（见图\ref{fig:simple-rnn}的$o$）。
    \begin{itemize}
        \item 第一步就是决定细胞状态需（见图\ref{fig:simple-rnn}的$f$）要丢弃哪些信息。这部分操作是通过一个称为忘记门的sigmoid单元来处理的。它通过查看和信息来输出一个0-1之间的向量，该向量里面的0-1值表示细胞状态中的哪些信息保留或丢弃多少。0表示不保留，1表示都保留。
        \item 第二步是决定给细胞状态添加哪些新的信息。这一步又分为两个步骤，首先，利用和通过一个称为输入门的操作来决定更新哪些信息。然后利用和通过一个tanh层得到新的候选细胞信息，这些信息可能会被更新到细胞信息中。
        \item 第三步将更新旧的细胞信息$C_{t-1}$，变为新的细胞信息$C_{t}$。更新的规则就是通过忘记门选择忘记旧细胞信息的一部分，通过输入门选择添加候选细胞信息$C_{t}$的一部分得到新的细胞信息$C_{t}$。更新完细胞状态后需要根据输入的和来判断输出细胞的哪些状态特征，这里需要将输入经过一个称为输出门的sigmoid层得到判断条件，然后将细胞状态经过tanh层得到一个-1~1之间值的向量，该向量与输出门得到的判断条件相乘就得到了最终该RNN单元的输出。
    \end{itemize}
    
    
    
    
    
    
    
    \begin{figure}[!htbp]
        \centering
        \begin{subfigure}[b]{0.45\textwidth}
          \includegraphics[width=\textwidth]{RNN.pdf}
          \caption{}
          \label{fig:simple-rnn}
        \end{subfigure}%
        ~% add desired spacing
        \begin{subfigure}[b]{0.45\textwidth}
          \includegraphics[width=\textwidth]{LSTM.pdf}
          \caption{}
          \label{fig:lstm}
        \end{subfigure}
        ~% add desired spacing
    
        \bicaption{循环神经网络。(a) 循环神经网络基本结构，(b) 长短期记忆网络 。}{RNN.(a)Basic structure of recurrent neural network(LSTM), (b)Long Short-Term Memory(LSTM) .}
        \label{fig:rnn}
    \end{figure}
    
    
    \item \textbf{Embedding方法}
    Embedding在数学上表示一个映射：$f:X \rightarrow Y$  ， 也就是一个函数。其中该函数满足两个性质：injective （单射的）：即单射函数，每个X只有唯一的Y对应;structure-preserving（结构保存）：比如在X所属的空间上  ，那么映射后在Y所属空间上同理  。那么对于word embedding, 就是找到一个映射(函数)将单词(word)映射到另外一个空间(其中这个映射具有injective和structure-preserving的特点), 生成在一个新的空间上的表达，该表达就是word representation.
    
    
\end{itemize}


\subsection{增量学习方法}
\citep{Geng2009}增量学习是一种机器学习范式，其中，每当出现新示例并根据新示例调整所学内容时，学习过程就会发生。增量学习与传统机器学习最显着的区别在于，它不假定在学习过程开始之前就可以提供足够的训练集，但是随着时间的流逝，会出现训练示例。增量学习被定义为机器学习体系结构通过馈送新数据而不丢失先前学习的知识来不断改进学习模型的能力。

已针对诸如图像分类和对象之类的问题来解决该问题，以解决\emph{灾难性遗忘}问题，该现象使旧类的性能急剧下降\citep{li2017learning,rebuffi2017icarl,shmelkov2017incremental}。一些研究保留了属于先前任务的一小部分数据，并在处理新问题时使用它们来保留旧任务的准确性。随机或根据相关性度量\citep{hinton2015distilling,rebuffi2017icarl}选择要存储的样本集。


\subsection{激活函数}在多层神经网络中，上层节点的输出和下层节点的输入之间具有一个函数关系，这个函数称为激活函数。常见的激活函数包括Sigmoid(见公式：\ref{eqn:Sigmoid})、tanh(见公式：\ref{eqn:tanh})、ReLU(见公式：\ref{eqn:ReLU})、LeakyReLU(见公式：\ref{eqn:LeakyReLU})、ELU(见公式：\ref{eqn:ELU})等，这些非线性的函数使得神经网络具有更强的特征建模能力。

\begin{subequations}
	\begin{equation}
	\label{eqn:Sigmoid}
	Sigmoid(x)=\frac{1}{1+e^{-x}}
	\end{equation}
	
	\begin{equation}
	\label{eqn:tanh}
	\tanh (x)=\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}
	\end{equation}
	
	\begin{equation}
	\label{eqn:ReLU}
	Relu(x)=max(0,x)
	\end{equation}

	\begin{equation}
	\label{eqn:LeakyReLU}
	LeakyReLU(x)=\max (\alpha x, x)
	\end{equation}
	
	\begin{equation}
	\label{eqn:ELU}
	ELU(x)=\left\{\begin{array}{ll}
x, & \text { if } x>0 \\
\alpha\left(e^{x}-1\right), & \text { otherwise }
\end{array}\right.
	\end{equation}

\end{subequations}


\section{小结}
通过对TLS/SSL协议的研究，可以发现，在HTTPS通信过程中，能够暴露出可以用于流量分析的特征。深度学习在不同的领域均取得了优秀的成果，使用深度学习处理流量分类问题是一个重要的发展趋势。